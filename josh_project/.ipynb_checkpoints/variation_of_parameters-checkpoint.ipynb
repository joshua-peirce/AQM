{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63960d3b-53b7-49ab-b98d-e0c92373c4a1",
   "metadata": {},
   "source": [
    "# In this notebook, I will describe how to use variation of parameters to estimate a slater-type orbital as a linear combination of gaussian-type orbitals\n",
    "## Specifically, I will consider the caes of a hydrogen atom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbe51c2-d5a7-41ba-9d81-7e0ec70a72fb",
   "metadata": {},
   "source": [
    "### Previous work:\n",
    "Thankfully, the overlap $S$ matrix, as well as the kinetic energy $T$ matrix and the coulomb potential energy $V$ matrix has been calculated for me in terms of the standard deviations of these gaussians:\n",
    "$$\\newcommand{\\ket}[1]{\\left|{#1}\\right\\rangle}$$\n",
    "$$\\newcommand{\\bra}[1]{\\left\\langle{#1}\\right|}$$\n",
    "$$\\begin{align*}\n",
    "S_{pq} &= \\left ( \\frac{\\pi}{\\alpha_p + \\alpha_q} \\right ) ^ {3/2}\\\\\n",
    "T_{pq} &= 3 \\frac{\\alpha_p \\alpha_q \\pi^{3/2}}{\\left(\\alpha_p + \\alpha_q\\right)^{5/2}}\\\\\n",
    "V_{pq} &= -\\frac{2\\pi}{\\alpha_p + \\alpha_q}\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2347710c-29cf-4df1-a116-3fb73e43eddc",
   "metadata": {},
   "source": [
    "### My work:\n",
    "The slater-type orbital we would like to approximate is represented as a linear combination of the gaussian type orbitals:\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\ket{s} &= \\displaystyle\\sum_i C_i \\ket{i}\\\\\n",
    "\\ket{i} &= \\exp\\left(\\alpha_i r^2\\right)\n",
    "\\end{align*}\n",
    "$$\n",
    "It remains to optimize the values of the coefficients $C_i$ and the parameters in the gaussians $\\alpha_i$. I will do this with gradient descent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc269d7-2075-42db-87af-4c9f7de22426",
   "metadata": {},
   "source": [
    "### How it works:\n",
    "The variational principle states that for any state with a variational parameter, nature will choose the value of that parameter that *minimizes* the energy. Thus, to optimize the linear combination of gaussians to most faithfully represent the slater-type orbital, the energy of this linear combination of gaussians must be minimized. This reduces the quantum mechanics problem to a more abstract optimization problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27402831-4ef2-43ce-ae87-420848e07e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First, I import the necessary libraries and set constants with regards to the learning parameters\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "PI_3_2 = math.pi ** 1.5\n",
    "N = 6 #number of terms used in linear combination\n",
    "\n",
    "#These can be tuned; I just found that these values work well.\n",
    "ALPHA_LEARNING_RATE = 0.1\n",
    "COEFF_LEARNING_RATE = 0.1\n",
    "DELTA_A = 0.001\n",
    "DELTA_C = 0.001\n",
    "\n",
    "NUM_ITERS = 10 ** 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923ff422-2349-4b1a-9dab-830e7dd0fa69",
   "metadata": {},
   "source": [
    "Then, I set up the functions for calculating the energy as described above. It is important to note here that the energy of a linear combination of states is defined as:\n",
    "$$\n",
    "\\begin{equation*}\n",
    "E_\\psi = \\frac{\\bra{\\psi} \\hat{H} \\ket{\\psi}}{\\bra{\\psi}\\ket{\\psi}}\n",
    "\\end{equation*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae1b1d6b-af54-4be0-ab85-e212560ec420",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_overlap(ap, aq):\n",
    "    return PI_3_2 / ((ap + aq) ** 1.5)\n",
    "\n",
    "def calc_KE(ap, aq):\n",
    "    return 3 * PI_3_2 * (ap * aq) / (ap + aq) ** 2.5\n",
    "\n",
    "def calc_PE(ap, aq):\n",
    "    return -2 * math.pi / (ap + aq)\n",
    "\n",
    "def calc_single_E(ap, aq):\n",
    "    return calc_KE(ap, aq) + calc_PE(ap, aq)\n",
    "\n",
    "def calc_norm(c, a):\n",
    "    o = 0\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            o += c[i] * c[j] * calc_overlap(a[i], a[j])\n",
    "    return o\n",
    "\n",
    "def calc_composite_E(c, a):\n",
    "     E = 0\n",
    "     for i in range(N):\n",
    "         for j in range(N):\n",
    "             E += c[i] * c[j] * calc_single_E(a[i], a[j])\n",
    "     return E / calc_norm(c, a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c3af4e-7077-4b5c-9cd8-af4d1c38587f",
   "metadata": {},
   "source": [
    "Now, I will implement the gradient descent algorithm. How it works is it calculates the direction of steepest descent for each of the parameters (each value of $\\alpha$ and $C$) using a crude method of calculating the derivative (simply taking the slope of the local secant line as the slope of the tangent line). It then adjusts them in that direction an amount scaled by the learning rate parameters. Note: if alpha ever goes negative, the gaussian it represents now blows up to infinity, and it no longer represents a physical state. This would break all physical sense and all our calculations, so to prevent this from happening, I scale the change to alpha by the value of alpha itself. This way, it will never subtract something greater than alpha from alpha, keeping its value always positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c924fdea-2ae9-4f85-83f0-e5e2429def05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(c, a):\n",
    "    #Vary the parameters to see the direction of steepest descent.\n",
    "    #Start with alphas and then move on to coefficients\n",
    "    E_0 = calc_composite_E(c, a)\n",
    "    #Computing alphas\n",
    "    gradients_a = []\n",
    "    gradients_c = []\n",
    "    for i in range(N):\n",
    "        a[i] += DELTA_A\n",
    "        gradients_a.append((calc_composite_E(c, a) - E_0) / DELTA_A)\n",
    "        a[i] -= DELTA_A\n",
    "    for i in range(N):\n",
    "        c[i] += DELTA_C\n",
    "        gradients_c.append((calc_composite_E(c, a) - E_0) / DELTA_C)\n",
    "        c[i] -= DELTA_C\n",
    "    a -= gradients_a * a # scaled by the alpha values so they never go negative\n",
    "    c -= gradients_c\n",
    "    return c, a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504eca00-15e9-4128-bfb3-8e5a5307b75c",
   "metadata": {},
   "source": [
    "Now, I assign random values to the starting parameters, and let the code run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e26ba59-8883-4a7d-996f-2761a454deeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.82756178 0.83292796 0.32551525 0.53784354 0.25101611 0.14072509] [0.76627919 0.57237301 0.77900288 0.09414339 0.98226739 0.87722718] -0.47011282659269915\n",
      "[0.76607533 0.78577546 0.47412792 0.13854227 0.28604556 0.28232596] [4.9848178  0.24199469 0.81998077 0.07654736 1.11947666 0.908502  ] -0.4983800616517317\n",
      "[0.71462183 0.71518807 0.51706889 0.12995186 0.46849517 0.29386621] [6.15404235 0.21745521 0.6101318  0.07233519 1.41707786 0.97906057] -0.4986126018431273\n",
      "[0.67941274 0.43018902 0.80350655 0.08598077 0.63714058 0.36840718] [7.31905903 0.1510322  0.39686229 0.06752776 1.59771275 0.96955186] -0.4988456478232414\n",
      "[0.64044544 0.18236265 0.84415926 0.03005855 0.68852208 0.54577424] [8.24965452 0.08635314 0.27846613 0.10394562 1.66449476 0.79153904] -0.4991432005194156\n",
      "[0.61930921 0.10173736 0.63169763 0.10134249 0.78416304 0.81211018] [9.02225188 0.07314855 0.22158339 0.10741953 1.83181123 0.5999825 ] -0.49907790398803714\n",
      "[0.62401197 0.08364993 0.46982187 0.06718933 0.90350893 1.01235236] [9.7727179  0.06515856 0.1604662  0.15757493 1.82992558 0.4922281 ] -0.49914142449334886\n",
      "[0.64939171 0.05599715 0.31995494 0.20685019 0.99437188 1.06616545] [10.32336985  0.06081008  0.12932487  0.18326577  1.79207155  0.45894622] -0.49923714637744826\n",
      "[0.65786281 0.05605443 0.20493249 0.33205196 1.02011893 1.10097084] [10.72630548  0.05843545  0.12719377  0.16161749  1.82321161  0.46226102] -0.4992738444316636\n",
      "[0.66321552 0.05500481 0.21283566 0.3255077  1.0420928  1.14270891] [11.0727343   0.05692329  0.15855197  0.13723535  1.85870552  0.46321502] -0.499292826379718\n"
     ]
    }
   ],
   "source": [
    "c = np.random.rand(N)\n",
    "a = np.random.rand(N)\n",
    "\n",
    "#If you instead want a rigged start, these gave really good results:\n",
    "#c = np.array([0.82756178 0.83292796 0.32551525 0.53784354 0.25101611 0.14072509])\n",
    "#a = np.array([0.76627919 0.57237301 0.77900288 0.09414339 0.98226739 0.87722718])\n",
    "\n",
    "for i in range(NUM_ITERS):\n",
    "    c, a = step(c, a)\n",
    "    if i % int(NUM_ITERS / 10) == 0:\n",
    "        print(c, a, calc_composite_E(c, a))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5aec06-925d-4b85-93fd-e4a2d3a3d30f",
   "metadata": {},
   "source": [
    "The values should converge to -0.5, as that is the theoretical limit, as determined without using approximations. Note: re-running the program will produce slightly different results, since the initial parameters are randomly set."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
